{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01bf454",
   "metadata": {},
   "source": [
    "# Universal Information Extraction Benchmark on BioRED Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ea7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f2c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388c20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")\n",
    "\n",
    "from src.common.utils import load_jsonl, save_predictions\n",
    "from src.common.metrics import get_metrics\n",
    "from src.common.data import generative_collate_fn\n",
    "from src.models.uie.data import UIEDataset\n",
    "from src.models.uie.inference import run_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e0bc1",
   "metadata": {},
   "source": [
    "Initialize model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3396463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32102, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32102, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32102, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32102, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"luyaojie/uie-large-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"luyaojie/uie-large-en\")\n",
    "\n",
    "device = torch.device('cuda:5')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05ac6b",
   "metadata": {},
   "source": [
    "### Zero-shot Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de2335",
   "metadata": {},
   "source": [
    "Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf46bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_jsonl(\"../../data/biored/test.jsonl\")\n",
    "test_dataset = UIEDataset(data=data, dataset_name='biored', tokenizer=tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=generative_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487d37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<spot> gene or gene product <spot> disease or phenotypic feature <spot> '\n",
      " 'chemical or drug <spot> genomic or protein variant <spot> species <spot> '\n",
      " 'cell line <asoc> is associated with <asoc> positively correlates with <asoc> '\n",
      " 'negatively correlates with <asoc> binds to <asoc> is cotreated with <asoc> '\n",
      " 'is compared to <asoc> converts to <asoc> interacts with drug <extra_id_2> '\n",
      " 'Allelic expression imbalance of human mu opioid receptor (OPRM1) caused by '\n",
      " 'variant A118G. As a primary target for opioid drugs and peptides, the mu '\n",
      " 'opioid receptor (OPRM1) plays a key role in pain perception and addiction. '\n",
      " 'Genetic variants of OPRM1 have been implicated in predisposition to drug '\n",
      " 'addiction, in particular the single nucleotide polymorphism A118G, leading '\n",
      " 'to an N40D substitution, with an allele frequency of 10-32%, and uncertain '\n",
      " 'functions. We have measured allele-specific mRNA expression of OPRM1 in '\n",
      " 'human autopsy brain tissues, using A118G as a marker. In 8 heterozygous '\n",
      " 'samples measured, the A118 mRNA allele was 1.5-2.5-fold more abundant than '\n",
      " 'the G118 allele. Transfection into Chinese hamster ovary cells of a cDNA '\n",
      " 'representing only the coding region of OPRM1, carrying adenosine, guanosine, '\n",
      " 'cytidine, and thymidine in position 118, resulted in 1.5-fold lower mRNA '\n",
      " 'levels only for OPRM1-G118, and more than 10-fold lower OPRM1 protein '\n",
      " 'levels, measured by Western blotting and receptor binding assay. After '\n",
      " 'transfection and inhibition of transcription with actinomycin D, analysis of '\n",
      " 'mRNA turnover failed to reveal differences in mRNA stability between A118 '\n",
      " 'and G118 alleles, indicating a defect in transcription or mRNA maturation. '\n",
      " 'These results indicate that OPRM1-G118 is a functional variant with '\n",
      " 'deleterious effects on both mRNA and protein yield. Clarifying the '\n",
      " 'functional relevance of polymorphisms associated with susceptibility to a '\n",
      " 'complex disorder such as drug addiction provides a foundation for clinical '\n",
      " 'association studies.')\n"
     ]
    }
   ],
   "source": [
    "pprint(test_dataset[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4674d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<extra_id_0> <extra_id_0> species <extra_id_5> human <extra_id_1> '\n",
      " '<extra_id_0> gene or gene product <extra_id_5> mu opioid receptor '\n",
      " '<extra_id_0> is associated with <extra_id_5> pain <extra_id_1> <extra_id_0> '\n",
      " 'is associated with <extra_id_5> drug addiction <extra_id_1> <extra_id_1> '\n",
      " '<extra_id_0> genomic or protein variant <extra_id_5> A118G <extra_id_1> '\n",
      " '<extra_id_0> disease or phenotypic feature <extra_id_5> pain <extra_id_1> '\n",
      " '<extra_id_0> disease or phenotypic feature <extra_id_5> drug addiction '\n",
      " '<extra_id_0> is associated with <extra_id_5> A118G <extra_id_1> <extra_id_1> '\n",
      " '<extra_id_0> species <extra_id_5> Chinese hamster <extra_id_1> <extra_id_0> '\n",
      " 'gene or gene product <extra_id_5> OPRM1 <extra_id_1> <extra_id_0> chemical '\n",
      " 'or drug <extra_id_5> actinomycin D <extra_id_1> <extra_id_1>')\n"
     ]
    }
   ],
   "source": [
    "pprint(test_dataset[1]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d33e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ec7a3cb27e4beb9a1c3aaf7449d365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running inference:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ../../predictions/uie/zero-shot/biored.jsonl\n"
     ]
    }
   ],
   "source": [
    "predictions = run_inference(model=model, dataloader=test_loader, tokenizer=tokenizer)\n",
    "\n",
    "save_predictions(predictions, \"../../predictions/uie/zero-shot\", \"biored.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bf2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity F1: 0.0000\n",
      "Relation F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = get_metrics(f\"../../predictions/uie/zero-shot/biored.jsonl\")\n",
    "\n",
    "print(f\"\\nEntity F1: {metrics['entity_f1']:.4f}\")\n",
    "print(f\"Relation F1: {metrics['relation_f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
